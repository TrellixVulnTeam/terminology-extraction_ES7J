{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36016c3e-31e7-469a-9bee-ff7ee2a7e475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>iate_%</th>\n",
       "      <th>headword</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ NOUN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOUN ADP NOUN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADV</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOUN ADP DET NOUN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOUN ADP ADJ NOUN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADP NOUN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADJ ADJ NOUN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADP</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pattern  iate_%  headword  quality\n",
       "0               NOUN    0.34         0        1\n",
       "1           ADJ NOUN    0.10         1        1\n",
       "2      NOUN ADP NOUN    0.03         0        1\n",
       "3                ADV    0.03         0        0\n",
       "4  NOUN ADP DET NOUN    0.03         1        1\n",
       "5                ADJ    0.02         0        1\n",
       "6  NOUN ADP ADJ NOUN    0.01         0        1\n",
       "7           ADP NOUN    0.01         1        1\n",
       "8       ADJ ADJ NOUN    0.01         2        1\n",
       "9                ADP    0.01         0        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pattern_n = pd.read_csv('patterns_nl.txt', delimiter = '\\t')\n",
    "pattern_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12909f07-3ce0-4892-98a0-f5d5f8b590b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hanhtran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 39.6MB/s]                    \n",
      "2021-06-10 11:55:20 INFO: Downloading default packages for language: nl (Dutch)...\n",
      "2021-06-10 11:55:22 INFO: File exists: /Users/hanhtran/stanza_resources/nl/default.zip.\n",
      "2021-06-10 11:55:26 INFO: Finished downloading models and saved to /Users/hanhtran/stanza_resources.\n",
      "2021-06-10 11:55:26 INFO: Loading these models for language: nl (Dutch):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | alpino  |\n",
      "| pos       | alpino  |\n",
      "| lemma     | alpino  |\n",
      "=======================\n",
      "\n",
      "2021-06-10 11:55:26 INFO: Use device: cpu\n",
      "2021-06-10 11:55:26 INFO: Loading: tokenize\n",
      "2021-06-10 11:55:26 INFO: Loading: pos\n",
      "2021-06-10 11:55:26 INFO: Loading: lemma\n",
      "2021-06-10 11:55:26 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import stanza\n",
    "stanza.download('nl')\n",
    "nlp = stanza.Pipeline(lang='nl', processors='tokenize,pos,lemma')\n",
    "\n",
    "def count_freq(preds, gts):\n",
    "    preds_len = [len(x.split(' ')) for x in preds]\n",
    "    gts_len = [len(x.split(' ')) for x in gts]\n",
    "    print(Counter(preds_len))\n",
    "    print(Counter(gts_len))\n",
    "\n",
    "def evaluation_metrics(pred, gt):\n",
    "    TP = len(set(pred) & set(gt)) \n",
    "    FP = len(set(pred)-set(gt))\n",
    "    FN = len(set(gt)-set(pred))\n",
    "    precision = round((TP/(TP+FP))*100, 2)\n",
    "    recall = round((TP/(TP+FN))*100,2)\n",
    "    f1_score = round((2 * precision * recall) / (precision + recall),2)\n",
    "    return precision, recall, f1_score \n",
    "\n",
    "def lemma(li):\n",
    "    new_list = []\n",
    "    for t in li:\n",
    "        doc = nlp(str(t))\n",
    "        doc1 = ' '.join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "        doc1 = re.sub('-',' ',doc1)\n",
    "        doc1 = re.sub(' +', ' ',doc1)\n",
    "        new_list.append(doc1)\n",
    "    new_list = [s for s in new_list if len(s) >= 2]\n",
    "    return new_list\n",
    "\n",
    "def get_term_(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for token, label in zip(tokens, labels):\n",
    "            if label == 'B':\n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "            # Check b_pos = 0 không\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4db1e8-69b7-41a6-96f9-724833ca63da",
   "metadata": {},
   "source": [
    "1. ADJ NOUN -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737f7121-5bf4-4185-a923-b2f31b0eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adj_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if (b_pos != 0) and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                    b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                    c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                    if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b_word.upos == 'ADJ'):\n",
    "                        terms.append(' '.join([b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2e8d1-3858-4a73-9d97-e32d3c55a43d",
   "metadata": {},
   "source": [
    "2. NOUN ADP NOUN - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b651bd9-17d2-4e34-988b-a0d69ab1c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_adp_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0 and i+1 < len(tokens):\n",
    "                    if (tokens[i] != '') and (tokens[i] != ' ') and (tokens[i+1] != '') and (tokens[i+1] != ' ') and (len(nlp(str(tokens[i])).sentences) > 0 and len(nlp(str(tokens[i+1])).sentences) > 0 and len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        a1_word = nlp(str(tokens[i+1])).sentences[0].words[0] \n",
    "                        a_word = nlp(str(tokens[i])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN')and (c_word.text != 'None') and (a_word.text != 'None') and (a1_word.text != 'None') and ((a_word.upos == 'ADP') and (a1_word.upos == 'NOUN')):\n",
    "                            terms.append(' '.join(term + [a_word.text] + [a1_word.text]))                               \n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        \n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower() for x in final_terms]\n",
    "    return final_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77339d1e-01b0-4216-9350-603999de2a28",
   "metadata": {},
   "source": [
    "3. NOUN ADP DET NOUN - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2917b0-f316-4134-955a-d276bcbe8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_adp_det_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                #adj_noun_adj_noun\n",
    "                if (b_pos != 0) and (i + 1 < len(tokens)) and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (tokens[b_pos] != '') and (tokens[b_pos] != ' ') and (tokens[i] != '') and (tokens[i] != ' ') and (tokens[i+1] != '') and (tokens[i+1] != ' ') and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0) and (len(nlp(str(tokens[i])).sentences) > 0) and  (len(nlp(str(tokens[i+1])).sentences) > 0): \n",
    "                    a1_word = nlp(str(tokens[i+1])).sentences[0].words[0]\n",
    "                    a_word = nlp(str(tokens[i])).sentences[0].words[0]\n",
    "                    b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                    c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                    # Check vị trí b_pos - 1: terms.append()\n",
    "                    if (c_word.text != 'None') and (b_word.text != 'None') and (a_word.text != 'None') and (a1_word.text != 'None') and (c_word.upos == 'ADP') and ((b_word.upos == 'NOUN') and (a_word.upos == 'DET') and (a1_word.upos == 'NOUN')):\n",
    "                        terms.append(' '.join([b_word.text] + term + [a_word.text] + [a1_word.text]))\n",
    "                                \n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "            # check b_pos - 1\n",
    "        \n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower() for x in final_terms]\n",
    "    return final_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad3a21d-edcb-427f-a299-237e223f60a2",
   "metadata": {},
   "source": [
    "4. NOUN ADP ADJ NOUN - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b0b742-b237-4add-98cf-85e586fdca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_adp_adj_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0 and i + 2 < len(tokens):\n",
    "                    if (tokens[i] != '') and (tokens[i] != ' ') and (tokens[i+1] != '') and (tokens[i+1] != ' ') and (tokens[i+2] != '') and (tokens[i+2] != ' ') and (tokens[b_pos] != '') and (tokens[b_pos] != ' ') and (len(nlp(str(tokens[i])).sentences) > 0 and len(nlp(str(tokens[i+1])).sentences) > 0 and len(nlp(str(tokens[i+2])).sentences) > 0 and len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        a2_word = nlp(str(tokens[i+2])).sentences[0].words[0] \n",
    "                        a1_word = nlp(str(tokens[i+1])).sentences[0].words[0] \n",
    "                        a_word = nlp(str(tokens[i])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (a_word.text != 'None') and (a1_word.text != 'None') and (a2_word.text != 'None') and (a_word.upos == 'ADP') and (a1_word.upos == 'ADJ') and (a2_word.upos == 'NOUN'):\n",
    "                            terms.append(' '.join(term + [a_word.text] + [a1_word.text] +[a2_word.text]))   \n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce9d45-1d7a-480a-b840-cc8c0dccc323",
   "metadata": {},
   "source": [
    "5. ADP NOUN - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67b4e0a-f121-4eb8-8510-0a733d60371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adp_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if (b_pos != 0) and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                    b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                    c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                    if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b_word.upos == 'ADP'):\n",
    "                        terms.append(' '.join([b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d521e-27e2-4c99-bf00-98620a03c03f",
   "metadata": {},
   "source": [
    "6. ADJ ADJ NOUN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f2c769-74b8-4e66-bb52-4c043daa9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adj_adj_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0:\n",
    "                    #ADJ ADJ NOUN              \n",
    "                    if (tokens[b_pos - 2] != '') and (tokens[b_pos - 2] != ' ') and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 2])).sentences) > 0 and len(nlp(str(tokens[b_pos - 1])).sentences) > 0 and len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        b1_word = nlp(str(tokens[b_pos - 2])).sentences[0].words[0] \n",
    "                        b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b1_word.text != 'None') and ((b_word.upos == 'ADJ') and (b1_word.upos == 'ADJ')):\n",
    "                            terms.append(' '.join([b1_word.text] +[b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5cf232-b9a8-4717-9bcb-ee33e32e5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_evaluation(domain_path, preds_path, rule=None):\n",
    "    groundtruth = pd.read_csv(domain_path, sep='\t', engine='python',header=None)\n",
    "    gt = list(groundtruth[0])\n",
    "    predictions = pkl.load(open(preds_path, 'rb'))\n",
    "    if rule == 'adj_noun':\n",
    "        preds =  get_term_adj_noun(predictions)\n",
    "    elif rule == 'noun_adp_noun':\n",
    "        preds =  get_term_noun_adp_noun(predictions)\n",
    "    elif rule == 'noun_adp_det_noun':\n",
    "        preds = get_term_noun_adp_det_noun(predictions)\n",
    "    elif rule == 'noun_adp_adj_noun':\n",
    "        preds = get_term_noun_adp_adj_noun(predictions)\n",
    "    elif rule == 'adp_noun':\n",
    "        preds = get_term_adp_noun(predictions)\n",
    "    elif rule == 'adj_adj_noun':\n",
    "        preds = get_term_adj_adj_noun(predictions)\n",
    "    else:\n",
    "        preds =  get_term_(predictions)\n",
    "    stop_words = set(stopwords.words('dutch'))\n",
    "    pred_terms =  set(preds) - set(stop_words)\n",
    "    pred_terms = [x for x in pred_terms if len(x)>1]\n",
    "    pred_terms = [x.lower().strip() for x in pred_terms]\n",
    "    pred_terms = [re.sub(' -','-', x) for x in pred_terms]\n",
    "    pred_terms = [re.sub('- ','-', x) for x in pred_terms]\n",
    "    pred_terms = [re.sub('\\(','', x) for x in pred_terms]\n",
    "    pred_terms = [re.sub('\\/','', x) for x in pred_terms]\n",
    "    precision, recall, f1 = evaluation_metrics(pred_terms, gt)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da87e87c-f610-4ed2-8c8f-10641592bb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NON_PATTERN_P</th>\n",
       "      <th>NON_PATTERN_R</th>\n",
       "      <th>NON_PATTERN_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_bert_htfl.pkl</td>\n",
       "      <td>60.40</td>\n",
       "      <td>59.50</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann_bert_wind.pkl</td>\n",
       "      <td>56.45</td>\n",
       "      <td>75.43</td>\n",
       "      <td>64.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ann_bert_equi.pkl</td>\n",
       "      <td>65.92</td>\n",
       "      <td>75.95</td>\n",
       "      <td>70.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ann_bert_corp.pkl</td>\n",
       "      <td>61.21</td>\n",
       "      <td>69.63</td>\n",
       "      <td>65.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nes_bert_htfl.pkl</td>\n",
       "      <td>63.54</td>\n",
       "      <td>58.83</td>\n",
       "      <td>61.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nes_bert_wind.pkl</td>\n",
       "      <td>59.80</td>\n",
       "      <td>68.35</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nes_bert_equi.pkl</td>\n",
       "      <td>67.70</td>\n",
       "      <td>72.47</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nes_bert_corp.pkl</td>\n",
       "      <td>61.03</td>\n",
       "      <td>66.87</td>\n",
       "      <td>63.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DOMAIN  NON_PATTERN_P  NON_PATTERN_R  NON_PATTERN_F1\n",
       "0  ann_bert_htfl.pkl          60.40          59.50           59.95\n",
       "1  ann_bert_wind.pkl          56.45          75.43           64.57\n",
       "2  ann_bert_equi.pkl          65.92          75.95           70.58\n",
       "3  ann_bert_corp.pkl          61.21          69.63           65.15\n",
       "4  nes_bert_htfl.pkl          63.54          58.83           61.09\n",
       "5  nes_bert_wind.pkl          59.80          68.35           63.79\n",
       "6  nes_bert_equi.pkl          67.70          72.47           70.00\n",
       "7  nes_bert_corp.pkl          61.03          66.87           63.82"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/hanhtran/Documents/terminology-extraction/ACTER/'\n",
    "domain_paths = [path+'nl/htfl/annotations/htfl_nl_terms.ann', path+'nl/wind/annotations/wind_nl_terms.ann',\n",
    "                path+'nl/equi/annotations/equi_nl_terms.ann',path+'nl/corp/annotations/corp_nl_terms.ann',\n",
    "                path+'nl/htfl/annotations/htfl_nl_terms_nes.ann', path+'nl/wind/annotations/wind_nl_terms_nes.ann',\n",
    "                path+'nl/equi/annotations/equi_nl_terms_nes.ann',path+'nl/corp/annotations/corp_nl_terms_nes.ann',\n",
    "               ]\n",
    "preds_paths = ['ann_bert_htfl.pkl','ann_bert_wind.pkl','ann_bert_equi.pkl', 'ann_bert_corp.pkl',\n",
    "              'nes_bert_htfl.pkl','nes_bert_wind.pkl','nes_bert_equi.pkl', 'nes_bert_corp.pkl']\n",
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p)\n",
    "    results.append([p,pre, rec, f1])\n",
    "raw_res = pd.DataFrame(results,columns=['DOMAIN','NON_PATTERN_P','NON_PATTERN_R','NON_PATTERN_F1'])\n",
    "raw_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a5336e-02a9-417c-9e3c-3ea7547ccca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p, 'adj_noun')\n",
    "    results.append([p,pre, rec, f1])\n",
    "adj_noun = pd.DataFrame(results,columns=['DOMAIN','ADJ_NOUN_P','ADJ_NOUN_R','ADJ_NOUN_F1'])\n",
    "adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27516c07-da55-48e8-a7bc-cd77e4cd8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p, 'noun_adp_noun')\n",
    "    results.append([p,pre, rec, f1])\n",
    "noun_adp_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_ADP_NOUN_P','NOUN_ADP_NOUN_R','NOUN_ADP_NOUN_F1'])\n",
    "noun_adp_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310708e5-ab46-408e-abcb-53af1233e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p, 'noun_adp_det_noun')\n",
    "    results.append([p,pre, rec, f1])\n",
    "noun_adp_det_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_ADP_DET_NOUN_P','NOUN_ADP_DET_NOUN_R','NOUN_ADP_DET_NOUN_F1'])\n",
    "noun_adp_det_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94c049-48bc-45a1-868a-9d42d6d7a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p, 'noun_adp_adj_noun')\n",
    "    results.append([p,pre, rec, f1])\n",
    "noun_adp_adj_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_ADP_ADJ_NOUN_P','NOUN_ADP_ADJ_NOUN_R','NOUN_ADP_ADJ_NOUN_F1'])\n",
    "noun_adp_adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b29531-8be9-4403-86f4-5b4909162005",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p, 'adp_noun')\n",
    "    results.append([p,pre, rec, f1])\n",
    "adp_noun = pd.DataFrame(results,columns=['DOMAIN','ADP_NOUN_P','ADP_NOUN_R','ADP_NOUN_F1'])\n",
    "adp_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ff8ca-87f7-420b-b591-57df6a2aba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    pre, rec, f1 = term_evaluation(d,p, 'adj_adj_noun')\n",
    "    results.append([p,pre, rec, f1])\n",
    "adj_adj_noun = pd.DataFrame(results,columns=['DOMAIN','ADJ_ADJ_NOUN_P','ADJ_ADJ_NOUN_R','ADJ_ADJ_NOUN_F1'])\n",
    "adj_adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478be51-c793-413e-b013-a95284349feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ls = [adj_noun, noun_adp_noun, noun_adp_det_noun, noun_adp_adj_noun, adp_noun, adj_adj_noun]\n",
    "\n",
    "for d in df_ls:\n",
    "    raw_res = raw_res.merge(d, on='DOMAIN', how='left')\n",
    "raw_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be34cf3-fd03-4a8b-8728-22f8b0f0ad99",
   "metadata": {},
   "source": [
    "Integrate all version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aaa1178-d919-4844-add0-9aba163b935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hanhtran/Documents/terminology-extraction/patterns/nl_domains'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d62bdd-bbb0-499e-9743-85e53735d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd36acb-d92c-470d-b628-084ca4422baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/hanhtran/Documents/terminology-extraction/patterns/nl_domains/nl_filtering/'\n",
    "non_pattern = pd.read_csv(path + 'non_partern.csv', index_col=0)\n",
    "adj_noun = pd.read_csv(path + 'adj_noun.csv', index_col=0)\n",
    "adj_adj_noun = pd.read_csv(path + 'adj_adj_noun.csv', index_col=0)\n",
    "adp_noun = pd.read_csv(path + 'adp_noun.csv', index_col=0)\n",
    "noun_adp_adj_noun = pd.read_csv(path + 'noun_adp_adj_noun.csv', index_col=0)\n",
    "noun_adp_det_noun = pd.read_csv(path + 'noun_adp_det_noun.csv', index_col=0)\n",
    "noun_adp_noun = pd.read_csv(path + 'noun_adp_noun.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9710b66-a6c1-46f4-95b7-5eb13d176c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NON_PATTERN_P</th>\n",
       "      <th>NON_PATTERN_R</th>\n",
       "      <th>NON_PATTERN_F1</th>\n",
       "      <th>ADJ_NOUN_P</th>\n",
       "      <th>ADJ_NOUN_R</th>\n",
       "      <th>ADJ_NOUN_F1</th>\n",
       "      <th>ADJ_ADJ_NOUN_P</th>\n",
       "      <th>ADJ_ADJ_NOUN_R</th>\n",
       "      <th>ADJ_ADJ_NOUN_F1</th>\n",
       "      <th>...</th>\n",
       "      <th>ADP_NOUN_F1</th>\n",
       "      <th>NOUN_ADP_ADJ_NOUN_P</th>\n",
       "      <th>NOUN_ADP_ADJ_NOUN_R</th>\n",
       "      <th>NOUN_ADP_ADJ_NOUN_F1</th>\n",
       "      <th>NOUN_ADP_DET_NOUN_P</th>\n",
       "      <th>NOUN_ADP_DET_NOUN_R</th>\n",
       "      <th>NOUN_ADP_DET_NOUN_F1</th>\n",
       "      <th>NOUN_ADP_NOUN_P</th>\n",
       "      <th>NOUN_ADP_NOUN_R</th>\n",
       "      <th>NOUN_ADP_NOUN_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/gdrive/MyDrive/TermEval/nl_domains/ann_bert_h...</td>\n",
       "      <td>60.40</td>\n",
       "      <td>59.50</td>\n",
       "      <td>59.95</td>\n",
       "      <td>55.74</td>\n",
       "      <td>64.80</td>\n",
       "      <td>59.93</td>\n",
       "      <td>59.87</td>\n",
       "      <td>59.98</td>\n",
       "      <td>59.92</td>\n",
       "      <td>...</td>\n",
       "      <td>53.60</td>\n",
       "      <td>59.29</td>\n",
       "      <td>59.55</td>\n",
       "      <td>59.42</td>\n",
       "      <td>60.34</td>\n",
       "      <td>59.50</td>\n",
       "      <td>59.92</td>\n",
       "      <td>54.29</td>\n",
       "      <td>59.50</td>\n",
       "      <td>56.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/gdrive/MyDrive/TermEval/nl_domains/ann_bert_w...</td>\n",
       "      <td>56.45</td>\n",
       "      <td>75.43</td>\n",
       "      <td>64.57</td>\n",
       "      <td>47.10</td>\n",
       "      <td>79.57</td>\n",
       "      <td>59.17</td>\n",
       "      <td>54.79</td>\n",
       "      <td>75.43</td>\n",
       "      <td>63.47</td>\n",
       "      <td>...</td>\n",
       "      <td>57.57</td>\n",
       "      <td>54.62</td>\n",
       "      <td>75.43</td>\n",
       "      <td>63.36</td>\n",
       "      <td>56.45</td>\n",
       "      <td>75.43</td>\n",
       "      <td>64.57</td>\n",
       "      <td>50.53</td>\n",
       "      <td>75.53</td>\n",
       "      <td>60.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/gdrive/MyDrive/TermEval/nl_domains/ann_bert_e...</td>\n",
       "      <td>65.92</td>\n",
       "      <td>75.95</td>\n",
       "      <td>70.58</td>\n",
       "      <td>53.29</td>\n",
       "      <td>78.97</td>\n",
       "      <td>63.64</td>\n",
       "      <td>64.55</td>\n",
       "      <td>75.95</td>\n",
       "      <td>69.79</td>\n",
       "      <td>...</td>\n",
       "      <td>65.55</td>\n",
       "      <td>65.39</td>\n",
       "      <td>75.95</td>\n",
       "      <td>70.28</td>\n",
       "      <td>65.31</td>\n",
       "      <td>75.95</td>\n",
       "      <td>70.23</td>\n",
       "      <td>60.34</td>\n",
       "      <td>76.02</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/gdrive/MyDrive/TermEval/nl_domains/ann_bert_c...</td>\n",
       "      <td>61.21</td>\n",
       "      <td>69.63</td>\n",
       "      <td>65.15</td>\n",
       "      <td>52.82</td>\n",
       "      <td>76.12</td>\n",
       "      <td>62.36</td>\n",
       "      <td>59.54</td>\n",
       "      <td>69.72</td>\n",
       "      <td>64.23</td>\n",
       "      <td>...</td>\n",
       "      <td>57.38</td>\n",
       "      <td>59.37</td>\n",
       "      <td>70.20</td>\n",
       "      <td>64.33</td>\n",
       "      <td>61.16</td>\n",
       "      <td>69.63</td>\n",
       "      <td>65.12</td>\n",
       "      <td>53.13</td>\n",
       "      <td>72.21</td>\n",
       "      <td>61.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/gdrive/MyDrive/TermEval/nl_domains/nes_bert_h...</td>\n",
       "      <td>63.54</td>\n",
       "      <td>58.83</td>\n",
       "      <td>61.09</td>\n",
       "      <td>58.29</td>\n",
       "      <td>64.11</td>\n",
       "      <td>61.06</td>\n",
       "      <td>63.08</td>\n",
       "      <td>59.27</td>\n",
       "      <td>61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>54.80</td>\n",
       "      <td>62.51</td>\n",
       "      <td>58.87</td>\n",
       "      <td>60.64</td>\n",
       "      <td>63.48</td>\n",
       "      <td>58.83</td>\n",
       "      <td>61.07</td>\n",
       "      <td>57.66</td>\n",
       "      <td>58.92</td>\n",
       "      <td>58.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  NON_PATTERN_P  \\\n",
       "0  /gdrive/MyDrive/TermEval/nl_domains/ann_bert_h...          60.40   \n",
       "1  /gdrive/MyDrive/TermEval/nl_domains/ann_bert_w...          56.45   \n",
       "2  /gdrive/MyDrive/TermEval/nl_domains/ann_bert_e...          65.92   \n",
       "3  /gdrive/MyDrive/TermEval/nl_domains/ann_bert_c...          61.21   \n",
       "4  /gdrive/MyDrive/TermEval/nl_domains/nes_bert_h...          63.54   \n",
       "\n",
       "   NON_PATTERN_R  NON_PATTERN_F1  ADJ_NOUN_P  ADJ_NOUN_R  ADJ_NOUN_F1  \\\n",
       "0          59.50           59.95       55.74       64.80        59.93   \n",
       "1          75.43           64.57       47.10       79.57        59.17   \n",
       "2          75.95           70.58       53.29       78.97        63.64   \n",
       "3          69.63           65.15       52.82       76.12        62.36   \n",
       "4          58.83           61.09       58.29       64.11        61.06   \n",
       "\n",
       "   ADJ_ADJ_NOUN_P  ADJ_ADJ_NOUN_R  ADJ_ADJ_NOUN_F1  ...  ADP_NOUN_F1  \\\n",
       "0           59.87           59.98            59.92  ...        53.60   \n",
       "1           54.79           75.43            63.47  ...        57.57   \n",
       "2           64.55           75.95            69.79  ...        65.55   \n",
       "3           59.54           69.72            64.23  ...        57.38   \n",
       "4           63.08           59.27            61.12  ...        54.80   \n",
       "\n",
       "   NOUN_ADP_ADJ_NOUN_P  NOUN_ADP_ADJ_NOUN_R  NOUN_ADP_ADJ_NOUN_F1  \\\n",
       "0                59.29                59.55                 59.42   \n",
       "1                54.62                75.43                 63.36   \n",
       "2                65.39                75.95                 70.28   \n",
       "3                59.37                70.20                 64.33   \n",
       "4                62.51                58.87                 60.64   \n",
       "\n",
       "   NOUN_ADP_DET_NOUN_P  NOUN_ADP_DET_NOUN_R  NOUN_ADP_DET_NOUN_F1  \\\n",
       "0                60.34                59.50                 59.92   \n",
       "1                56.45                75.43                 64.57   \n",
       "2                65.31                75.95                 70.23   \n",
       "3                61.16                69.63                 65.12   \n",
       "4                63.48                58.83                 61.07   \n",
       "\n",
       "   NOUN_ADP_NOUN_P  NOUN_ADP_NOUN_R  NOUN_ADP_NOUN_F1  \n",
       "0            54.29            59.50             56.78  \n",
       "1            50.53            75.53             60.55  \n",
       "2            60.34            76.02             67.28  \n",
       "3            53.13            72.21             61.22  \n",
       "4            57.66            58.92             58.28  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = non_pattern.merge(adj_noun, on = 'DOMAIN', how='left')\n",
    "df = df.merge(adj_adj_noun, on = 'DOMAIN', how='left')\n",
    "df = df.merge(adp_noun, on = 'DOMAIN', how='left')\n",
    "df = df.merge(noun_adp_adj_noun, on = 'DOMAIN', how='left')\n",
    "df = df.merge(noun_adp_det_noun, on = 'DOMAIN', how='left')\n",
    "df = df.merge(noun_adp_noun, on = 'DOMAIN', how='left')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43c41e74-16a2-43bf-abde-4927786791ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NON_PATTERN_F1</th>\n",
       "      <th>ADJ_NOUN_F1</th>\n",
       "      <th>ADJ_ADJ_NOUN_F1</th>\n",
       "      <th>ADP_NOUN_F1</th>\n",
       "      <th>NOUN_ADP_ADJ_NOUN_F1</th>\n",
       "      <th>NOUN_ADP_DET_NOUN_F1</th>\n",
       "      <th>NOUN_ADP_NOUN_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_bert_htfl.pkl</td>\n",
       "      <td>59.95</td>\n",
       "      <td>59.93</td>\n",
       "      <td>59.92</td>\n",
       "      <td>53.60</td>\n",
       "      <td>59.42</td>\n",
       "      <td>59.92</td>\n",
       "      <td>56.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann_bert_wind.pkl</td>\n",
       "      <td>64.57</td>\n",
       "      <td>59.17</td>\n",
       "      <td>63.47</td>\n",
       "      <td>57.57</td>\n",
       "      <td>63.36</td>\n",
       "      <td>64.57</td>\n",
       "      <td>60.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ann_bert_equi.pkl</td>\n",
       "      <td>70.58</td>\n",
       "      <td>63.64</td>\n",
       "      <td>69.79</td>\n",
       "      <td>65.55</td>\n",
       "      <td>70.28</td>\n",
       "      <td>70.23</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ann_bert_corp.pkl</td>\n",
       "      <td>65.15</td>\n",
       "      <td>62.36</td>\n",
       "      <td>64.23</td>\n",
       "      <td>57.38</td>\n",
       "      <td>64.33</td>\n",
       "      <td>65.12</td>\n",
       "      <td>61.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nes_bert_htfl.pkl</td>\n",
       "      <td>61.09</td>\n",
       "      <td>61.06</td>\n",
       "      <td>61.12</td>\n",
       "      <td>54.80</td>\n",
       "      <td>60.64</td>\n",
       "      <td>61.07</td>\n",
       "      <td>58.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nes_bert_wind.pkl</td>\n",
       "      <td>63.79</td>\n",
       "      <td>59.93</td>\n",
       "      <td>62.92</td>\n",
       "      <td>58.34</td>\n",
       "      <td>62.90</td>\n",
       "      <td>63.79</td>\n",
       "      <td>60.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nes_bert_equi.pkl</td>\n",
       "      <td>70.00</td>\n",
       "      <td>63.78</td>\n",
       "      <td>69.35</td>\n",
       "      <td>65.53</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.46</td>\n",
       "      <td>67.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nes_bert_corp.pkl</td>\n",
       "      <td>63.82</td>\n",
       "      <td>61.32</td>\n",
       "      <td>63.31</td>\n",
       "      <td>57.47</td>\n",
       "      <td>63.14</td>\n",
       "      <td>63.79</td>\n",
       "      <td>60.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DOMAIN  NON_PATTERN_F1  ADJ_NOUN_F1  ADJ_ADJ_NOUN_F1  \\\n",
       "0  ann_bert_htfl.pkl           59.95        59.93            59.92   \n",
       "1  ann_bert_wind.pkl           64.57        59.17            63.47   \n",
       "2  ann_bert_equi.pkl           70.58        63.64            69.79   \n",
       "3  ann_bert_corp.pkl           65.15        62.36            64.23   \n",
       "4  nes_bert_htfl.pkl           61.09        61.06            61.12   \n",
       "5  nes_bert_wind.pkl           63.79        59.93            62.92   \n",
       "6  nes_bert_equi.pkl           70.00        63.78            69.35   \n",
       "7  nes_bert_corp.pkl           63.82        61.32            63.31   \n",
       "\n",
       "   ADP_NOUN_F1  NOUN_ADP_ADJ_NOUN_F1  NOUN_ADP_DET_NOUN_F1  NOUN_ADP_NOUN_F1  \n",
       "0        53.60                 59.42                 59.92             56.78  \n",
       "1        57.57                 63.36                 64.57             60.55  \n",
       "2        65.55                 70.28                 70.23             67.28  \n",
       "3        57.38                 64.33                 65.12             61.22  \n",
       "4        54.80                 60.64                 61.07             58.28  \n",
       "5        58.34                 62.90                 63.79             60.76  \n",
       "6        65.53                 69.70                 69.46             67.07  \n",
       "7        57.47                 63.14                 63.79             60.48  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DOMAIN'] = [x.split('/')[-1] for x in df['DOMAIN']]\n",
    "cols = [col for col in df.columns if 'DOMAIN' in col or '_F1' in col]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "963f8392-d884-4b27-ad8c-67f8e42f5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = df[cols].set_index('DOMAIN').T\n",
    "f1_df.to_csv('nl_iate_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a425076-b83a-406f-b033-6c0dd42bf2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>DOMAIN</th>\n",
       "      <th>ann_bert_htfl.pkl</th>\n",
       "      <th>ann_bert_wind.pkl</th>\n",
       "      <th>ann_bert_equi.pkl</th>\n",
       "      <th>ann_bert_corp.pkl</th>\n",
       "      <th>nes_bert_htfl.pkl</th>\n",
       "      <th>nes_bert_wind.pkl</th>\n",
       "      <th>nes_bert_equi.pkl</th>\n",
       "      <th>nes_bert_corp.pkl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NON_PATTERN_F1</th>\n",
       "      <td>59.95</td>\n",
       "      <td>64.57</td>\n",
       "      <td>70.58</td>\n",
       "      <td>65.15</td>\n",
       "      <td>61.09</td>\n",
       "      <td>63.79</td>\n",
       "      <td>70.00</td>\n",
       "      <td>63.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_F1</th>\n",
       "      <td>59.93</td>\n",
       "      <td>59.17</td>\n",
       "      <td>63.64</td>\n",
       "      <td>62.36</td>\n",
       "      <td>61.06</td>\n",
       "      <td>59.93</td>\n",
       "      <td>63.78</td>\n",
       "      <td>61.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_ADJ_NOUN_F1</th>\n",
       "      <td>59.92</td>\n",
       "      <td>63.47</td>\n",
       "      <td>69.79</td>\n",
       "      <td>64.23</td>\n",
       "      <td>61.12</td>\n",
       "      <td>62.92</td>\n",
       "      <td>69.35</td>\n",
       "      <td>63.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP_NOUN_F1</th>\n",
       "      <td>53.60</td>\n",
       "      <td>57.57</td>\n",
       "      <td>65.55</td>\n",
       "      <td>57.38</td>\n",
       "      <td>54.80</td>\n",
       "      <td>58.34</td>\n",
       "      <td>65.53</td>\n",
       "      <td>57.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_ADJ_NOUN_F1</th>\n",
       "      <td>59.42</td>\n",
       "      <td>63.36</td>\n",
       "      <td>70.28</td>\n",
       "      <td>64.33</td>\n",
       "      <td>60.64</td>\n",
       "      <td>62.90</td>\n",
       "      <td>69.70</td>\n",
       "      <td>63.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_DET_NOUN_F1</th>\n",
       "      <td>59.92</td>\n",
       "      <td>64.57</td>\n",
       "      <td>70.23</td>\n",
       "      <td>65.12</td>\n",
       "      <td>61.07</td>\n",
       "      <td>63.79</td>\n",
       "      <td>69.46</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_NOUN_F1</th>\n",
       "      <td>56.78</td>\n",
       "      <td>60.55</td>\n",
       "      <td>67.28</td>\n",
       "      <td>61.22</td>\n",
       "      <td>58.28</td>\n",
       "      <td>60.76</td>\n",
       "      <td>67.07</td>\n",
       "      <td>60.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "DOMAIN                ann_bert_htfl.pkl  ann_bert_wind.pkl  ann_bert_equi.pkl  \\\n",
       "NON_PATTERN_F1                    59.95              64.57              70.58   \n",
       "ADJ_NOUN_F1                       59.93              59.17              63.64   \n",
       "ADJ_ADJ_NOUN_F1                   59.92              63.47              69.79   \n",
       "ADP_NOUN_F1                       53.60              57.57              65.55   \n",
       "NOUN_ADP_ADJ_NOUN_F1              59.42              63.36              70.28   \n",
       "NOUN_ADP_DET_NOUN_F1              59.92              64.57              70.23   \n",
       "NOUN_ADP_NOUN_F1                  56.78              60.55              67.28   \n",
       "\n",
       "DOMAIN                ann_bert_corp.pkl  nes_bert_htfl.pkl  nes_bert_wind.pkl  \\\n",
       "NON_PATTERN_F1                    65.15              61.09              63.79   \n",
       "ADJ_NOUN_F1                       62.36              61.06              59.93   \n",
       "ADJ_ADJ_NOUN_F1                   64.23              61.12              62.92   \n",
       "ADP_NOUN_F1                       57.38              54.80              58.34   \n",
       "NOUN_ADP_ADJ_NOUN_F1              64.33              60.64              62.90   \n",
       "NOUN_ADP_DET_NOUN_F1              65.12              61.07              63.79   \n",
       "NOUN_ADP_NOUN_F1                  61.22              58.28              60.76   \n",
       "\n",
       "DOMAIN                nes_bert_equi.pkl  nes_bert_corp.pkl  \n",
       "NON_PATTERN_F1                    70.00              63.82  \n",
       "ADJ_NOUN_F1                       63.78              61.32  \n",
       "ADJ_ADJ_NOUN_F1                   69.35              63.31  \n",
       "ADP_NOUN_F1                       65.53              57.47  \n",
       "NOUN_ADP_ADJ_NOUN_F1              69.70              63.14  \n",
       "NOUN_ADP_DET_NOUN_F1              69.46              63.79  \n",
       "NOUN_ADP_NOUN_F1                  67.07              60.48  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bf2841c-23e5-4a2c-88cb-adac52cf5032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NON_PATTERN_P</th>\n",
       "      <th>NON_PATTERN_R</th>\n",
       "      <th>NON_PATTERN_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_bert_htfl.pkl</td>\n",
       "      <td>60.40</td>\n",
       "      <td>59.50</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann_bert_wind.pkl</td>\n",
       "      <td>56.45</td>\n",
       "      <td>75.43</td>\n",
       "      <td>64.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ann_bert_equi.pkl</td>\n",
       "      <td>65.92</td>\n",
       "      <td>75.95</td>\n",
       "      <td>70.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ann_bert_corp.pkl</td>\n",
       "      <td>61.21</td>\n",
       "      <td>69.63</td>\n",
       "      <td>65.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nes_bert_htfl.pkl</td>\n",
       "      <td>63.54</td>\n",
       "      <td>58.83</td>\n",
       "      <td>61.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nes_bert_wind.pkl</td>\n",
       "      <td>59.80</td>\n",
       "      <td>68.35</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nes_bert_equi.pkl</td>\n",
       "      <td>67.70</td>\n",
       "      <td>72.47</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nes_bert_corp.pkl</td>\n",
       "      <td>61.03</td>\n",
       "      <td>66.87</td>\n",
       "      <td>63.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DOMAIN  NON_PATTERN_P  NON_PATTERN_R  NON_PATTERN_F1\n",
       "0  ann_bert_htfl.pkl          60.40          59.50           59.95\n",
       "1  ann_bert_wind.pkl          56.45          75.43           64.57\n",
       "2  ann_bert_equi.pkl          65.92          75.95           70.58\n",
       "3  ann_bert_corp.pkl          61.21          69.63           65.15\n",
       "4  nes_bert_htfl.pkl          63.54          58.83           61.09\n",
       "5  nes_bert_wind.pkl          59.80          68.35           63.79\n",
       "6  nes_bert_equi.pkl          67.70          72.47           70.00\n",
       "7  nes_bert_corp.pkl          61.03          66.87           63.82"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[col for col in df.columns if 'DOMAIN' in col or 'NON_PATTERN' in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a262fe-2401-46ac-aed4-54d7f89c1221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
