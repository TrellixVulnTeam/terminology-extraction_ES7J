{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ebfd13-7fd3-41fa-92e8-0d37e7901c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hanhtran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-08-10 16:57:04 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-08-10 16:57:04 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2021-08-10 16:57:04 INFO: Use device: cpu\n",
      "2021-08-10 16:57:04 INFO: Loading: tokenize\n",
      "2021-08-10 16:57:04 INFO: Loading: pos\n",
      "2021-08-10 16:57:04 INFO: Loading: lemma\n",
      "2021-08-10 16:57:04 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import stanza\n",
    "# stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "\n",
    "def count_freq(preds, gts):\n",
    "    preds_len = [len(x.split(' ')) for x in preds]\n",
    "    gts_len = [len(x.split(' ')) for x in gts]\n",
    "    print(Counter(preds_len))\n",
    "    print(Counter(gts_len))\n",
    "\n",
    "def evaluation_metrics(pred, gt):\n",
    "    TP = len(set(pred) & set(gt)) \n",
    "    FP = len(set(pred)-set(gt))\n",
    "    FN = len(set(gt)-set(pred))\n",
    "    precision = round((TP/(TP+FP))*100, 2)\n",
    "    recall = round((TP/(TP+FN))*100,2)\n",
    "    f1_score = round((2 * precision * recall) / (precision + recall),2)\n",
    "    return precision, recall, f1_score \n",
    "\n",
    "def lemma(li):\n",
    "    new_list = []\n",
    "    for t in li:\n",
    "        doc = nlp(str(t))\n",
    "        doc1 = ' '.join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "        doc1 = re.sub('-',' ',doc1)\n",
    "        doc1 = re.sub(' +', ' ',doc1)\n",
    "        new_list.append(doc1)\n",
    "    new_list = [s for s in new_list if len(s) >= 2]\n",
    "    return new_list\n",
    "\n",
    "def get_term_(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for token, label in zip(tokens, labels):\n",
    "            if label == 'B':\n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "            # Check b_pos = 0 không\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c3cfd-78e4-479f-ae46-f9cdf792394e",
   "metadata": {},
   "source": [
    "|Patterns|%IATE|Head|\n",
    "|-|-|-|\n",
    "|NOUN NOUN\t        |0.15\t|1| \n",
    "|ADJ NOUN\t        |0.14\t|1| \n",
    "|ADJ NOUN NOUN\t    |0.04\t|2|\n",
    "|NOUN NOUN NOUN\t    |0.03\t|2|\n",
    "|NOUN ADP NOUN\t    |0.02\t|0| \n",
    "|ADJ ADJ NOUN\t    |0.01\t|2|\n",
    "|NOUN ADP ADJ NOUN\t|0.01\t|0|\n",
    "|ADJ NOUN NOUN NOUN\t|0.01\t|3|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e32f9f-a263-44e6-9410-6cf1f5d61a67",
   "metadata": {},
   "source": [
    "1. NOUN NOUN - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f85474a-033f-476c-9e8e-863008153b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0:\n",
    "                    if (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b_word.upos == 'NOUN'):\n",
    "                            terms.append(' '.join([b_word.text] + term))\n",
    "#                     if (tokens[i] != '') and (tokens[i] != ' ') and (len(nlp(str(tokens[i])).sentences) > 0):\n",
    "#                         a_word = nlp(str(tokens[i])).sentences[0].words[0]\n",
    "#                         if (a_word.text != 'None') and (a_word.upos == 'NOUN'):\n",
    "#                             terms.append(' '.join(term + [a_word.text]))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed307e2-5ef8-4d78-a376-bbeff0ee6fec",
   "metadata": {},
   "source": [
    "2. ADJ NOUN - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe57598-8ff9-4983-aa77-150449327222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adj_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if (b_pos != 0) and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                    b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                    c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                    if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b_word.upos == 'ADJ'):\n",
    "                        terms.append(' '.join([b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35896895-eaa1-41be-983d-61f75a9b3f2e",
   "metadata": {},
   "source": [
    "3. ADJ NOUN NOUN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363bf66a-941c-4adf-a03b-4ff1eadb1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adj_noun_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                # Check b_pos = 0 không\n",
    "                if (b_pos != 0) and (tokens[b_pos] != '') and (tokens[b_pos] != ' ') and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ')and (tokens[b_pos - 2] != '') and (tokens[b_pos - 2] != ' ') and (len(nlp(str(tokens[b_pos - 2])).sentences) > 0) and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                    b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                    b1_word = nlp(str(tokens[b_pos - 2])).sentences[0].words[0]\n",
    "                    c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                    if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b_word.upos == 'NOUN')and (b1_word.text != 'None') and (b1_word.upos == 'ADJ'):\n",
    "                        terms.append(' '.join([b1_word.text] +[b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "            # check b_pos - 1\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8839aa-9868-4bfd-b206-ffb98eb3e32f",
   "metadata": {},
   "source": [
    "4. NOUN NOUN NOUN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5c84c8-4329-4d9f-a90d-8e402ce2ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_noun_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0:\n",
    "                    #ADJ ADJ NOUN              \n",
    "                    if (tokens[b_pos - 2] != '') and (tokens[b_pos - 2] != ' ') and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 2])).sentences) > 0) and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        b1_word = nlp(str(tokens[b_pos - 2])).sentences[0].words[0] \n",
    "                        b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b1_word.text != 'None') and (b_word.upos == 'NOUN') and (b1_word.upos == 'NOUN'):\n",
    "                            terms.append(' '.join([b1_word.text] +[b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0454b-44ea-44ec-b570-3b67db43d21c",
   "metadata": {},
   "source": [
    "5. NOUN ADP NOUN - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f20cc67-13eb-4753-988c-ac38400976fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_adp_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0 and i+1 < len(tokens):\n",
    "                    if (tokens[i] != '') and (tokens[i] != ' ') and (tokens[i+1] != '') and (tokens[i+1] != ' ') and (len(nlp(str(tokens[i])).sentences) > 0) and (len(nlp(str(tokens[i+1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        a1_word = nlp(str(tokens[i+1])).sentences[0].words[0] \n",
    "                        a_word = nlp(str(tokens[i])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN')and (c_word.text != 'None') and (a_word.text != 'None') and (a1_word.text != 'None') and (a_word.upos == 'ADP') and (a1_word.upos == 'NOUN'):\n",
    "                            terms.append(' '.join(term + [a_word.text] + [a1_word.text]))                               \n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        \n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower() for x in final_terms]\n",
    "    return final_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8873ab-80ae-417c-8a99-662b8aef901c",
   "metadata": {},
   "source": [
    "6. ADJ ADJ NOUN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244bb7d2-93ae-40ce-afaa-672a44cc000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adj_adj_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0:\n",
    "                    #ADJ ADJ NOUN              \n",
    "                    if (tokens[b_pos - 2] != '') and (tokens[b_pos - 2] != ' ') and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 2])).sentences) > 0) and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        b1_word = nlp(str(tokens[b_pos - 2])).sentences[0].words[0] \n",
    "                        b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b1_word.text != 'None') and (b_word.upos == 'ADJ') and (b1_word.upos == 'ADJ'):\n",
    "                            terms.append(' '.join([b1_word.text] +[b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e65feb-4595-4e57-8d77-38aeb33b99eb",
   "metadata": {},
   "source": [
    "7. NOUN ADP ADJ NOUN - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6e695b-3ab4-48b2-a07f-2c30b411661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_noun_adp_adj_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                #Lưu vị trí B\n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0 and i + 2 < len(tokens):\n",
    "                    if (tokens[i] != '') and (tokens[i] != ' ') and (tokens[i+1] != '') and (tokens[i+1] != ' ') and (tokens[i+2] != '') and (tokens[i+2] != ' ') and (tokens[b_pos] != '') and (tokens[b_pos] != ' ') and (len(nlp(str(tokens[i])).sentences) > 0) and (len(nlp(str(tokens[i+1])).sentences) > 0) and (len(nlp(str(tokens[i+2])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        a2_word = nlp(str(tokens[i+2])).sentences[0].words[0] \n",
    "                        a1_word = nlp(str(tokens[i+1])).sentences[0].words[0] \n",
    "                        a_word = nlp(str(tokens[i])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (a_word.text != 'None') and (a1_word.text != 'None') and (a2_word.text != 'None') and (a_word.upos == 'ADP') and (a1_word.upos == 'ADJ') and (a2_word.upos == 'NOUN'):\n",
    "                            terms.append(' '.join(term + [a_word.text] + [a1_word.text] +[a2_word.text]))   \n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628c91-2e85-4b38-ab6f-c511c3643f71",
   "metadata": {},
   "source": [
    "8. ADJ NOUN NOUN NOUN - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a7e42e-a93b-4caf-b10f-b4aa5973bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_adj_noun_noun_noun(predictions):\n",
    "    all_term = []\n",
    "    for sentence in predictions:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for d in sentence:\n",
    "            tokens.extend(d.keys())\n",
    "            labels.extend(d.values())\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if labels[i] == 'I' and (i == 0 or labels[i - 1] == 'O'):\n",
    "                labels[i] = 'O'\n",
    "\n",
    "        terms = []\n",
    "        term = []\n",
    "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "            if label == 'B': \n",
    "                b_pos = i\n",
    "                term = [token]\n",
    "            elif label == 'I':\n",
    "                term.append(token)\n",
    "            elif len(term) > 0:\n",
    "                terms.append(' '.join(term))\n",
    "                if b_pos != 0:         \n",
    "                    if (tokens[b_pos - 3] != '') and (tokens[b_pos - 3] != ' ') and  (tokens[b_pos - 2] != '') and (tokens[b_pos - 2] != ' ') and (tokens[b_pos - 3] != '') and (tokens[b_pos - 3] != ' ') and (tokens[b_pos - 1] != '') and (tokens[b_pos - 1] != ' ') and (len(nlp(str(tokens[b_pos - 2])).sentences) > 0) and (len(nlp(str(tokens[b_pos - 3])).sentences) > 0) and (len(nlp(str(tokens[b_pos - 1])).sentences) > 0) and (len(nlp(str(tokens[b_pos])).sentences) > 0):\n",
    "                        b2_word = nlp(str(tokens[b_pos - 3])).sentences[0].words[0] \n",
    "                        b1_word = nlp(str(tokens[b_pos - 2])).sentences[0].words[0] \n",
    "                        b_word = nlp(str(tokens[b_pos - 1])).sentences[0].words[0]\n",
    "                        c_word = nlp(str(tokens[b_pos])).sentences[0].words[0]\n",
    "                        if (c_word.upos == 'NOUN') and (c_word.text != 'None') and (b_word.text != 'None') and (b1_word.text != 'None') and (b2_word.text != 'None') and (b_word.upos == 'NOUN') and (b1_word.upos == 'NOUN') and (b2_word.upos == 'ADJ'):\n",
    "                            terms.append(' '.join([b2_word.text] +[b1_word.text] +[b_word.text] + term))\n",
    "                term = []\n",
    "        if len(term) > 0:\n",
    "            terms.append(' '.join(term))\n",
    "        all_term.append(terms)\n",
    "    \n",
    "    final_terms = []\n",
    "    for i in all_term:\n",
    "        final_terms.extend(i)\n",
    "\n",
    "    final_terms = [x.lower().strip() for x in final_terms]\n",
    "    return final_terms    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22145374-f243-494a-bd58-6cb6718a2781",
   "metadata": {},
   "source": [
    "|Patterns|%IATE|Head|\n",
    "|-|-|-|\n",
    "|NOUN NOUN\t        |0.15\t|1| \n",
    "|ADJ NOUN\t        |0.14\t|1| \n",
    "|ADJ NOUN NOUN\t    |0.04\t|2|\n",
    "|NOUN NOUN NOUN\t    |0.03\t|2|\n",
    "|NOUN ADP NOUN\t    |0.02\t|0| \n",
    "|ADJ ADJ NOUN\t    |0.01\t|2|\n",
    "|NOUN ADP ADJ NOUN\t|0.01\t|0|\n",
    "|ADJ NOUN NOUN NOUN\t|0.01\t|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e308f30-fcb5-49ec-acaf-52ae82d2a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_evaluation(domain_path, preds_path, rule=None):\n",
    "    groundtruth = pd.read_csv(domain_path, sep='\t', engine='python',header=None)\n",
    "    gt = list(groundtruth[0])\n",
    "    predictions = pkl.load(open(preds_path, 'rb'))\n",
    "    if rule == 'adj_noun':\n",
    "        preds =  get_term_adj_noun(predictions)\n",
    "    elif rule == 'noun_noun':\n",
    "        preds =  get_term_noun_noun(predictions)\n",
    "    elif rule == 'adj_noun_noun':\n",
    "        preds = get_term_adj_noun_noun(predictions)\n",
    "    elif rule == 'noun_noun_noun':\n",
    "        preds = get_term_noun_noun_noun(predictions)\n",
    "    elif rule == 'noun_adp_noun':\n",
    "        preds = get_term_noun_adp_noun(predictions)\n",
    "    elif rule == 'adj_adj_noun':\n",
    "        preds = get_term_adj_adj_noun(predictions)\n",
    "    elif rule == 'noun_adp_adj_noun':\n",
    "        preds = get_term_noun_adp_adj_noun(predictions)\n",
    "    elif rule == 'adj_noun_noun_noun':\n",
    "        preds = get_term_adj_noun_noun_noun(predictions)\n",
    "    else:\n",
    "        preds =  get_term_(predictions)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    pred_terms =  set(preds) - set(stop_words)\n",
    "    pred_terms = [x for x in pred_terms if len(x)>1]\n",
    "    pred_terms = [x.lower().strip() for x in pred_terms]\n",
    "    pred_terms = [re.sub(' -','-', x) for x in pred_terms]\n",
    "    pred_terms = [re.sub('- ','-', x) for x in pred_terms]\n",
    "    pred_terms = [re.sub('\\(','', x) for x in pred_terms]\n",
    "    pred_terms = [re.sub('\\/','', x) for x in pred_terms]\n",
    "    precision, recall, f1 = evaluation_metrics(pred_terms, gt)\n",
    "    return f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ccc9a9-1da1-4c03-b813-b9c43cd50f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NON_PATTERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>40.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>23.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  NON_PATTERN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...        34.81\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...        40.62\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...        10.69\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...        20.20\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...        23.04\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...        29.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/hanhtran/Documents/terminology-extraction/ACTER/en/'\n",
    "path1= '/Users/hanhtran/Documents/terminology-extraction/patterns/en_domains/corp_wind/'\n",
    "path2= '/Users/hanhtran/Documents/terminology-extraction/patterns/en_domains/equi_wind/'\n",
    "path3= '/Users/hanhtran/Documents/terminology-extraction/patterns/en_domains/corp_equi/'\n",
    "\n",
    "domain_paths = [path+'equi/annotations/equi_en_terms.ann', path+'equi/annotations/equi_en_terms_nes.ann',\n",
    "               path+'corp/annotations/corp_en_terms.ann', path+'corp/annotations/corp_en_terms_nes.ann',\n",
    "               path+'wind/annotations/wind_en_terms.ann', path+'wind/annotations/wind_en_terms_nes.ann']\n",
    "preds_paths = [path1 + 'ann_xlnet_equi.pkl', path1 + 'nes_xlnet_equi.pkl',\n",
    "              path2 + 'ann_xlnet_corp.pkl', path2 + 'nes_xlnet_corp.pkl',\n",
    "              path3 + 'ann_xlnet_wind.pkl', path3 + 'nes_xlnet_wind.pkl']\n",
    "                \n",
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d, p)\n",
    "    results.append([p, f1])\n",
    "raw_res = pd.DataFrame(results,columns=['DOMAIN','NON_PATTERN'])\n",
    "raw_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c283973-b5e0-4aa2-900f-06b36ff6593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NOUN_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>35.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>41.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>11.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>26.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>30.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  NOUN_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...      35.87\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...      41.35\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...      11.07\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...      20.56\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...      26.10\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...      30.90"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1  = term_evaluation(d, p, 'noun_noun')\n",
    "    results.append([p, f1])\n",
    "noun_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_NOUN'])\n",
    "noun_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91e1a98-5d17-4541-93ad-ec0c551e7b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>ADJ_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>33.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>39.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>12.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>23.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  ADJ_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...     33.63\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...     39.64\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...     12.15\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...     20.27\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...     23.69\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...     29.44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d,  p, 'adj_noun')\n",
    "    results.append([p, f1])\n",
    "adj_noun = pd.DataFrame(results,columns=['DOMAIN','ADJ_NOUN'])\n",
    "adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed98b448-1b76-4e11-af58-4e4129beb7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>ADJ_NOUN_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>23.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  ADJ_NOUN_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...          34.69\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...          40.53\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...          10.67\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...          20.29\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...          23.30\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...          29.17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d, p, 'adj_noun_noun')\n",
    "    results.append([p, f1])\n",
    "adj_noun_noun = pd.DataFrame(results,columns=['DOMAIN','ADJ_NOUN_NOUN'])\n",
    "adj_noun_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e75cff91-d986-41dd-ae77-27807eb9a463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NOUN_NOUN_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>40.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>23.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  NOUN_NOUN_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...           34.56\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...           40.39\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...           10.65\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...           20.15\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...           23.49\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...           29.07"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d, p, 'noun_noun_noun')\n",
    "    results.append([p, f1])\n",
    "noun_noun_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_NOUN_NOUN'])\n",
    "noun_noun_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f9771e7-a878-4e94-b77f-9230c4332c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NOUN_ADP_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>39.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>22.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>28.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  NOUN_ADP_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...          34.05\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...          39.81\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...          10.68\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...          19.93\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...          22.53\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...          28.63"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d, p, 'noun_adp_noun')\n",
    "    results.append([p,f1])\n",
    "noun_adp_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_ADP_NOUN'])\n",
    "noun_adp_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65373261-d73f-4181-ac93-104822d9e893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>ADJ_ADJ_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>40.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  ADJ_ADJ_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...         34.68\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...         40.52\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...         10.68\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...         20.20\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...         22.95\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...         29.18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d,  p, 'adj_adj_noun')\n",
    "    results.append([p,f1])\n",
    "adj_adj_noun = pd.DataFrame(results,columns=['DOMAIN','ADJ_ADJ_NOUN'])\n",
    "adj_adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729f58fe-6843-4e75-9c1f-9c7e5f71bd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NOUN_ADP_ADJ_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>40.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>22.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  NOUN_ADP_ADJ_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...              34.61\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...              40.40\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...              10.59\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...              20.08\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...              22.83\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...              29.02"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d, p, 'noun_adp_adj_noun')\n",
    "    results.append([p,f1])\n",
    "noun_adp_adj_noun = pd.DataFrame(results,columns=['DOMAIN','NOUN_ADP_ADJ_NOUN'])\n",
    "noun_adp_adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fed11a7a-9569-4230-86f1-19f1cee28b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>ADJ_NOUN_NOUN_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>34.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>40.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>23.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/hanhtran/Documents/terminology-extracti...</td>\n",
       "      <td>29.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              DOMAIN  ADJ_NOUN_NOUN_NOUN\n",
       "0  /Users/hanhtran/Documents/terminology-extracti...               34.84\n",
       "1  /Users/hanhtran/Documents/terminology-extracti...               40.58\n",
       "2  /Users/hanhtran/Documents/terminology-extracti...               10.68\n",
       "3  /Users/hanhtran/Documents/terminology-extracti...               20.19\n",
       "4  /Users/hanhtran/Documents/terminology-extracti...               23.06\n",
       "5  /Users/hanhtran/Documents/terminology-extracti...               29.29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for d, p in zip(domain_paths, preds_paths):\n",
    "    f1 = term_evaluation(d, p, 'adj_noun_noun_noun')\n",
    "    results.append([p,f1])\n",
    "adj_noun_noun_noun = pd.DataFrame(results,columns=['DOMAIN','ADJ_NOUN_NOUN_NOUN'])\n",
    "adj_noun_noun_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d491f4e9-06dc-4616-984f-8ffc4487cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ls = [noun_noun, adj_noun, adj_noun_noun, noun_noun_noun ,\n",
    "         noun_adp_noun, adj_adj_noun,noun_adp_adj_noun,adj_noun_noun_noun]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee31379b-f26e-4037-9629-4ca13976a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in df_ls:\n",
    "    raw_res = raw_res.merge(d, on='DOMAIN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c37989d2-aaca-4fef-b0b0-3f86519c8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>NON_PATTERN</th>\n",
       "      <th>NOUN_NOUN</th>\n",
       "      <th>ADJ_NOUN</th>\n",
       "      <th>ADJ_NOUN_NOUN</th>\n",
       "      <th>NOUN_NOUN_NOUN</th>\n",
       "      <th>NOUN_ADP_NOUN</th>\n",
       "      <th>ADJ_ADJ_NOUN</th>\n",
       "      <th>NOUN_ADP_ADJ_NOUN</th>\n",
       "      <th>ADJ_NOUN_NOUN_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_xlnet_equi.pkl</td>\n",
       "      <td>34.81</td>\n",
       "      <td>35.87</td>\n",
       "      <td>33.63</td>\n",
       "      <td>34.69</td>\n",
       "      <td>34.56</td>\n",
       "      <td>34.05</td>\n",
       "      <td>34.68</td>\n",
       "      <td>34.61</td>\n",
       "      <td>34.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nes_xlnet_equi.pkl</td>\n",
       "      <td>40.62</td>\n",
       "      <td>41.35</td>\n",
       "      <td>39.64</td>\n",
       "      <td>40.53</td>\n",
       "      <td>40.39</td>\n",
       "      <td>39.81</td>\n",
       "      <td>40.52</td>\n",
       "      <td>40.40</td>\n",
       "      <td>40.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ann_xlnet_corp.pkl</td>\n",
       "      <td>10.69</td>\n",
       "      <td>11.07</td>\n",
       "      <td>12.15</td>\n",
       "      <td>10.67</td>\n",
       "      <td>10.65</td>\n",
       "      <td>10.68</td>\n",
       "      <td>10.68</td>\n",
       "      <td>10.59</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nes_xlnet_corp.pkl</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.56</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>20.15</td>\n",
       "      <td>19.93</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.08</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ann_xlnet_wind.pkl</td>\n",
       "      <td>23.04</td>\n",
       "      <td>26.10</td>\n",
       "      <td>23.69</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.49</td>\n",
       "      <td>22.53</td>\n",
       "      <td>22.95</td>\n",
       "      <td>22.83</td>\n",
       "      <td>23.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nes_xlnet_wind.pkl</td>\n",
       "      <td>29.25</td>\n",
       "      <td>30.90</td>\n",
       "      <td>29.44</td>\n",
       "      <td>29.17</td>\n",
       "      <td>29.07</td>\n",
       "      <td>28.63</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.02</td>\n",
       "      <td>29.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DOMAIN  NON_PATTERN  NOUN_NOUN  ADJ_NOUN  ADJ_NOUN_NOUN  \\\n",
       "0  ann_xlnet_equi.pkl        34.81      35.87     33.63          34.69   \n",
       "1  nes_xlnet_equi.pkl        40.62      41.35     39.64          40.53   \n",
       "2  ann_xlnet_corp.pkl        10.69      11.07     12.15          10.67   \n",
       "3  nes_xlnet_corp.pkl        20.20      20.56     20.27          20.29   \n",
       "4  ann_xlnet_wind.pkl        23.04      26.10     23.69          23.30   \n",
       "5  nes_xlnet_wind.pkl        29.25      30.90     29.44          29.17   \n",
       "\n",
       "   NOUN_NOUN_NOUN  NOUN_ADP_NOUN  ADJ_ADJ_NOUN  NOUN_ADP_ADJ_NOUN  \\\n",
       "0           34.56          34.05         34.68              34.61   \n",
       "1           40.39          39.81         40.52              40.40   \n",
       "2           10.65          10.68         10.68              10.59   \n",
       "3           20.15          19.93         20.20              20.08   \n",
       "4           23.49          22.53         22.95              22.83   \n",
       "5           29.07          28.63         29.18              29.02   \n",
       "\n",
       "   ADJ_NOUN_NOUN_NOUN  \n",
       "0               34.84  \n",
       "1               40.58  \n",
       "2               10.68  \n",
       "3               20.19  \n",
       "4               23.06  \n",
       "5               29.29  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_res['DOMAIN'] = [x.split('/')[-1] for x in raw_res['DOMAIN']]\n",
    "raw_res                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49f33751-d30b-4b52-98d1-d8331c1b5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_res.to_csv('en_iate_comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db993f41-522b-459e-b4f6-d619ee63b7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_xlnet_equi.pkl</th>\n",
       "      <th>nes_xlnet_equi.pkl</th>\n",
       "      <th>ann_xlnet_corp.pkl</th>\n",
       "      <th>nes_xlnet_corp.pkl</th>\n",
       "      <th>ann_xlnet_wind.pkl</th>\n",
       "      <th>nes_xlnet_wind.pkl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NON_PATTERN</th>\n",
       "      <td>34.81</td>\n",
       "      <td>40.62</td>\n",
       "      <td>10.69</td>\n",
       "      <td>20.2</td>\n",
       "      <td>23.04</td>\n",
       "      <td>29.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_NOUN</th>\n",
       "      <td>35.87</td>\n",
       "      <td>41.35</td>\n",
       "      <td>11.07</td>\n",
       "      <td>20.56</td>\n",
       "      <td>26.1</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN</th>\n",
       "      <td>33.63</td>\n",
       "      <td>39.64</td>\n",
       "      <td>12.15</td>\n",
       "      <td>20.27</td>\n",
       "      <td>23.69</td>\n",
       "      <td>29.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_NOUN</th>\n",
       "      <td>34.69</td>\n",
       "      <td>40.53</td>\n",
       "      <td>10.67</td>\n",
       "      <td>20.29</td>\n",
       "      <td>23.3</td>\n",
       "      <td>29.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_NOUN_NOUN</th>\n",
       "      <td>34.56</td>\n",
       "      <td>40.39</td>\n",
       "      <td>10.65</td>\n",
       "      <td>20.15</td>\n",
       "      <td>23.49</td>\n",
       "      <td>29.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_NOUN</th>\n",
       "      <td>34.05</td>\n",
       "      <td>39.81</td>\n",
       "      <td>10.68</td>\n",
       "      <td>19.93</td>\n",
       "      <td>22.53</td>\n",
       "      <td>28.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_ADJ_NOUN</th>\n",
       "      <td>34.68</td>\n",
       "      <td>40.52</td>\n",
       "      <td>10.68</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.95</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_ADJ_NOUN</th>\n",
       "      <td>34.61</td>\n",
       "      <td>40.4</td>\n",
       "      <td>10.59</td>\n",
       "      <td>20.08</td>\n",
       "      <td>22.83</td>\n",
       "      <td>29.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_NOUN_NOUN</th>\n",
       "      <td>34.84</td>\n",
       "      <td>40.58</td>\n",
       "      <td>10.68</td>\n",
       "      <td>20.19</td>\n",
       "      <td>23.06</td>\n",
       "      <td>29.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ann_xlnet_equi.pkl nes_xlnet_equi.pkl ann_xlnet_corp.pkl  \\\n",
       "NON_PATTERN                     34.81              40.62              10.69   \n",
       "NOUN_NOUN                       35.87              41.35              11.07   \n",
       "ADJ_NOUN                        33.63              39.64              12.15   \n",
       "ADJ_NOUN_NOUN                   34.69              40.53              10.67   \n",
       "NOUN_NOUN_NOUN                  34.56              40.39              10.65   \n",
       "NOUN_ADP_NOUN                   34.05              39.81              10.68   \n",
       "ADJ_ADJ_NOUN                    34.68              40.52              10.68   \n",
       "NOUN_ADP_ADJ_NOUN               34.61               40.4              10.59   \n",
       "ADJ_NOUN_NOUN_NOUN              34.84              40.58              10.68   \n",
       "\n",
       "                   nes_xlnet_corp.pkl ann_xlnet_wind.pkl nes_xlnet_wind.pkl  \n",
       "NON_PATTERN                      20.2              23.04              29.25  \n",
       "NOUN_NOUN                       20.56               26.1               30.9  \n",
       "ADJ_NOUN                        20.27              23.69              29.44  \n",
       "ADJ_NOUN_NOUN                   20.29               23.3              29.17  \n",
       "NOUN_NOUN_NOUN                  20.15              23.49              29.07  \n",
       "NOUN_ADP_NOUN                   19.93              22.53              28.63  \n",
       "ADJ_ADJ_NOUN                     20.2              22.95              29.18  \n",
       "NOUN_ADP_ADJ_NOUN               20.08              22.83              29.02  \n",
       "ADJ_NOUN_NOUN_NOUN              20.19              23.06              29.29  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = raw_res.T.rename(columns=raw_res.T.iloc[0]).drop(raw_res.T.index[0])\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c1c0e66-74df-4f1b-b99a-0a9d9aa8f7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_ann_xlnet_equi.pkl</th>\n",
       "      <th>percent_nes_xlnet_equi.pkl</th>\n",
       "      <th>percent_ann_xlnet_corp.pkl</th>\n",
       "      <th>percent_nes_xlnet_corp.pkl</th>\n",
       "      <th>percent_ann_xlnet_wind.pkl</th>\n",
       "      <th>percent_nes_xlnet_wind.pkl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NON_PATTERN</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_NOUN</th>\n",
       "      <td>3.05</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.78</td>\n",
       "      <td>13.28</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN</th>\n",
       "      <td>-3.39</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_NOUN</th>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_NOUN_NOUN</th>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_NOUN</th>\n",
       "      <td>-2.18</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_ADJ_NOUN</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_ADJ_NOUN</th>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_NOUN_NOUN</th>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    percent_ann_xlnet_equi.pkl  percent_nes_xlnet_equi.pkl  \\\n",
       "NON_PATTERN                               0.00                        0.00   \n",
       "NOUN_NOUN                                 3.05                        1.80   \n",
       "ADJ_NOUN                                 -3.39                       -2.41   \n",
       "ADJ_NOUN_NOUN                            -0.34                       -0.22   \n",
       "NOUN_NOUN_NOUN                           -0.72                       -0.57   \n",
       "NOUN_ADP_NOUN                            -2.18                       -1.99   \n",
       "ADJ_ADJ_NOUN                             -0.37                       -0.25   \n",
       "NOUN_ADP_ADJ_NOUN                        -0.57                       -0.54   \n",
       "ADJ_NOUN_NOUN_NOUN                        0.09                       -0.10   \n",
       "\n",
       "                    percent_ann_xlnet_corp.pkl  percent_nes_xlnet_corp.pkl  \\\n",
       "NON_PATTERN                               0.00                        0.00   \n",
       "NOUN_NOUN                                 3.55                        1.78   \n",
       "ADJ_NOUN                                 13.66                        0.35   \n",
       "ADJ_NOUN_NOUN                            -0.19                        0.45   \n",
       "NOUN_NOUN_NOUN                           -0.37                       -0.25   \n",
       "NOUN_ADP_NOUN                            -0.09                       -1.34   \n",
       "ADJ_ADJ_NOUN                             -0.09                        0.00   \n",
       "NOUN_ADP_ADJ_NOUN                        -0.94                       -0.59   \n",
       "ADJ_NOUN_NOUN_NOUN                       -0.09                       -0.05   \n",
       "\n",
       "                    percent_ann_xlnet_wind.pkl  percent_nes_xlnet_wind.pkl  \n",
       "NON_PATTERN                               0.00                        0.00  \n",
       "NOUN_NOUN                                13.28                        5.64  \n",
       "ADJ_NOUN                                  2.82                        0.65  \n",
       "ADJ_NOUN_NOUN                             1.13                       -0.27  \n",
       "NOUN_NOUN_NOUN                            1.95                       -0.62  \n",
       "NOUN_ADP_NOUN                            -2.21                       -2.12  \n",
       "ADJ_ADJ_NOUN                             -0.39                       -0.24  \n",
       "NOUN_ADP_ADJ_NOUN                        -0.91                       -0.79  \n",
       "ADJ_NOUN_NOUN_NOUN                        0.09                        0.14  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in list(final.columns):\n",
    "    final[col] = [float(x) for x in final[col]]\n",
    "    final['percent_'+ col] = round(final[col]*100/final[col].iloc[0],2) - 100\n",
    "\n",
    "final.filter(regex='percent_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "200f1659-7478-4952-b671-dbd8acd5da08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_ann_xlnet_corp.pkl</th>\n",
       "      <th>percent_ann_xlnet_equi.pkl</th>\n",
       "      <th>percent_ann_xlnet_wind.pkl</th>\n",
       "      <th>percent_nes_xlnet_corp.pkl</th>\n",
       "      <th>percent_nes_xlnet_equi.pkl</th>\n",
       "      <th>percent_nes_xlnet_wind.pkl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NON_PATTERN</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_NOUN</th>\n",
       "      <td>3.55</td>\n",
       "      <td>3.05</td>\n",
       "      <td>13.28</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.80</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN</th>\n",
       "      <td>13.66</td>\n",
       "      <td>-3.39</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_NOUN</th>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_NOUN_NOUN</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_NOUN</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_ADJ_NOUN</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN_ADP_ADJ_NOUN</th>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ_NOUN_NOUN_NOUN</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    percent_ann_xlnet_corp.pkl  percent_ann_xlnet_equi.pkl  \\\n",
       "NON_PATTERN                               0.00                        0.00   \n",
       "NOUN_NOUN                                 3.55                        3.05   \n",
       "ADJ_NOUN                                 13.66                       -3.39   \n",
       "ADJ_NOUN_NOUN                            -0.19                       -0.34   \n",
       "NOUN_NOUN_NOUN                           -0.37                       -0.72   \n",
       "NOUN_ADP_NOUN                            -0.09                       -2.18   \n",
       "ADJ_ADJ_NOUN                             -0.09                       -0.37   \n",
       "NOUN_ADP_ADJ_NOUN                        -0.94                       -0.57   \n",
       "ADJ_NOUN_NOUN_NOUN                       -0.09                        0.09   \n",
       "\n",
       "                    percent_ann_xlnet_wind.pkl  percent_nes_xlnet_corp.pkl  \\\n",
       "NON_PATTERN                               0.00                        0.00   \n",
       "NOUN_NOUN                                13.28                        1.78   \n",
       "ADJ_NOUN                                  2.82                        0.35   \n",
       "ADJ_NOUN_NOUN                             1.13                        0.45   \n",
       "NOUN_NOUN_NOUN                            1.95                       -0.25   \n",
       "NOUN_ADP_NOUN                            -2.21                       -1.34   \n",
       "ADJ_ADJ_NOUN                             -0.39                        0.00   \n",
       "NOUN_ADP_ADJ_NOUN                        -0.91                       -0.59   \n",
       "ADJ_NOUN_NOUN_NOUN                        0.09                       -0.05   \n",
       "\n",
       "                    percent_nes_xlnet_equi.pkl  percent_nes_xlnet_wind.pkl  \n",
       "NON_PATTERN                               0.00                        0.00  \n",
       "NOUN_NOUN                                 1.80                        5.64  \n",
       "ADJ_NOUN                                 -2.41                        0.65  \n",
       "ADJ_NOUN_NOUN                            -0.22                       -0.27  \n",
       "NOUN_NOUN_NOUN                           -0.57                       -0.62  \n",
       "NOUN_ADP_NOUN                            -1.99                       -2.12  \n",
       "ADJ_ADJ_NOUN                             -0.25                       -0.24  \n",
       "NOUN_ADP_ADJ_NOUN                        -0.54                       -0.79  \n",
       "ADJ_NOUN_NOUN_NOUN                       -0.10                        0.14  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.filter(regex='percent_')[['percent_ann_xlnet_corp.pkl', 'percent_ann_xlnet_equi.pkl', 'percent_ann_xlnet_wind.pkl',\n",
    "                                'percent_nes_xlnet_corp.pkl','percent_nes_xlnet_equi.pkl', 'percent_nes_xlnet_wind.pkl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab75d679-e320-4fb8-b7f8-c985d1a63818",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.filter(regex='percent_').to_csv('percent_comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ce98d-cd90-4f60-9f4e-50ceaf2fc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
