{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concerned-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/hanh/anaconda3/envs/termeval/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /home/hanh/anaconda3/envs/termeval/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/hanh/anaconda3/envs/termeval/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/hanh/anaconda3/envs/termeval/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: regex in /home/hanh/anaconda3/envs/termeval/lib/python3.8/site-packages (from nltk) (2021.3.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "skilled-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_gt = pd.read_csv('../ACTER/en/htfl/annotations/htfl_en_terms_nes.ann', sep='\t', engine='python',header=None)\n",
    "# en_preds = pd.read_csv('../results/en/bert_en_nes_predictions.csv')\n",
    "en_gt = pd.read_csv('../ACTER/fr/htfl/annotations/htfl_fr_terms_nes.ann', sep='\t', engine='python',header=None)\n",
    "en_preds = pd.read_csv('../results/fr/camembert_fr_nes_predictions.csv')\n",
    "preds = list(en_preds['predictions'])\n",
    "gts = list(en_gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "heavy-adolescent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 930, 2: 431, 3: 114, 4: 22, 5: 3, 6: 2})\n",
      "Counter({1: 1170, 2: 800, 3: 376, 4: 144, 5: 40, 6: 31, 7: 8, 8: 4, 10: 4, 13: 2, 11: 2, 29: 1, 14: 1, 9: 1, 21: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "preds_len = [len(x.split(' ')) for x in preds]\n",
    "gts_len = [len(x.split(' ')) for x in gts]\n",
    "print(Counter(preds_len))\n",
    "print(Counter(gts_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "successful-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a comparison of outcomes in patients in new york heart association [nyha] class ii heart failure when treated with eplerenone or placebo in addition to standard heart failure medicines'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(gts, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090 319 1271\n",
      "1409\n",
      "2361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.36, 46.17, 57.83)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P = TP/(TP+FP)\n",
    "# R =  TP/(TP+FN)\n",
    "def evaluation_metrics(pred, gt):\n",
    "    TP = len(set(pred) & set(gt)) \n",
    "    FP = len(set(pred)-set(gt))\n",
    "    FN = len(set(gt)-set(pred))\n",
    "    print(TP, FP, FN)\n",
    "    precision = round((TP/(TP+FP))*100, 2)\n",
    "    recall = round((TP/(TP+FN))*100,2)\n",
    "    f1_score = round((2 * precision * recall) / (precision + recall),2)\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "precision, recall, f1_score = evaluation_metrics(preds, gts)\n",
    "print(len(set(preds)))\n",
    "print(len(set(gts)))\n",
    "precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bronze-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stemming\n",
      "1259\n",
      "2103\n",
      "953 306 1150\n",
      "(75.69, 45.32, 56.69)\n",
      "After lemmatization\n",
      "1351\n",
      "2279\n",
      "1033 318 1246\n",
      "(76.46, 45.33, 56.92)\n",
      "After combined\n",
      "1258\n",
      "2102\n",
      "952 306 1150\n",
      "1394\n",
      "2361\n",
      "1088 306 1273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78.05, 46.08, 57.95)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "port = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "preds_stem = [port.stem(i) for i in preds]\n",
    "gts_stem = [port.stem(i) for i in gts]\n",
    "\n",
    "print('After stemming')\n",
    "print(len(set(preds_stem)))\n",
    "print(len(set(gts_stem)))\n",
    "print(evaluation_metrics(list(set(preds_stem)), list(set(gts_stem))))\n",
    "\n",
    "preds_lem = [wnl.lemmatize(i) for i in preds]\n",
    "gts_lem = [wnl.lemmatize(i) for i in gts]\n",
    "\n",
    "print('After lemmatization')\n",
    "print(len(set(preds_lem)))\n",
    "print(len(set((gts_lem))))\n",
    "print(evaluation_metrics(list(set(preds_lem)), list(set(gts_lem))))\n",
    "\n",
    "preds_com = [port.stem(wnl.lemmatize(i)) for i in preds]\n",
    "gts_com = [port.stem(wnl.lemmatize(i)) for i in gts]\n",
    "\n",
    "print('After combined')\n",
    "print(len(set(preds_com)))\n",
    "print(len(set((gts_com))))\n",
    "evaluation_metrics(list(set(preds_com)), list(set(gts_com)))\n",
    "\n",
    "preds_ =[x for x in preds if len(x) >= 2]\n",
    "gts_ =[x for x in gts if len(x) >= 2]\n",
    "print(len(set(preds_)))\n",
    "print(len(gts))\n",
    "evaluation_metrics(set(preds_), gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_gt = pd.read_csv('../ACTER/nl/htfl/annotations/htfl_nl_terms.ann', sep='\t', engine='python',header=None)\n",
    "fr_preds = pd.read_csv('../results/nl/bert_nl_ann_predictions.csv')\n",
    "preds = list(fr_preds['predictions'])\n",
    "gts = list(fr_gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score = evaluation_metrics(preds, gts)\n",
    "\n",
    "print(len(set(preds)))\n",
    "print(len(set(gts)))\n",
    "print(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ =[x for x in preds if len(x) >= 2]\n",
    "gts_ =[x for x in gts if len(x) >= 2]\n",
    "print(len(set(preds_)))\n",
    "print(len(gts))\n",
    "evaluation_metrics(set(preds_), gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "stemmer = FrenchStemmer()\n",
    "print(stemmer.stem('voudrais'))\n",
    "print(stemmer.stem('couvre'))\n",
    "print(stemmer.stem('dors'))\n",
    "print(stemmer.stem('animaux'))\n",
    "print(stemmer.stem('yeux'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-block",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
